{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9acac5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f44a4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = 'comentarios_Alvaro Delgado Uruguay_procesado_Ortografiado_sentimiento_analizado'\n",
    "df = pd.read_csv(f'{ruta}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85e410d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comentario</th>\n",
       "      <th>Autor</th>\n",
       "      <th>Likes_Comentario</th>\n",
       "      <th>Fecha_Publicacion_Comentario</th>\n",
       "      <th>URL_Video</th>\n",
       "      <th>Titulo_Video</th>\n",
       "      <th>Descripcion_Video</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Fecha_Publicacion_Video</th>\n",
       "      <th>Idioma</th>\n",
       "      <th>...</th>\n",
       "      <th>Comentario_nrc</th>\n",
       "      <th>Titulo_Video_afinn</th>\n",
       "      <th>Titulo_Video_nrc</th>\n",
       "      <th>Descripcion_Video_afinn</th>\n",
       "      <th>Descripcion_Video_nrc</th>\n",
       "      <th>Comentario_Polaridad</th>\n",
       "      <th>Comentario_Subjetividad</th>\n",
       "      <th>Tags_afinn</th>\n",
       "      <th>Tags_nrc</th>\n",
       "      <th>Categoria_Nombre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3746</th>\n",
       "      <td>Plata desapareció</td>\n",
       "      <td>@piglinslayer5159</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-07-22T22:08:26Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=NMf3uKHuTTs</td>\n",
       "      <td>álvaro delgado pidió renuncia intendente artig...</td>\n",
       "      <td>tras ser condenado caso investiga cobro irregu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-07-22T17:27:10Z</td>\n",
       "      <td>es-419</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>positivo:1, negativo:1</td>\n",
       "      <td>-4</td>\n",
       "      <td>miedo:2, negativo:4, tristeza:2, positivo:4, a...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>Buen reporte gracias, votante orgullosa ser ur...</td>\n",
       "      <td>@soguma2011</td>\n",
       "      <td>11</td>\n",
       "      <td>2024-10-28T02:27:04Z</td>\n",
       "      <td>https://www.youtube.com/watch?v=lxkUpiOCM9k</td>\n",
       "      <td>ballottage uruguay segunda vuelta candidatos d...</td>\n",
       "      <td>millones ciudadanos uruguayos asisten domingo ...</td>\n",
       "      <td>canal noticias canal argentina canal noticias ...</td>\n",
       "      <td>2024-10-28T01:38:41Z</td>\n",
       "      <td>es-419</td>\n",
       "      <td>...</td>\n",
       "      <td>anticipación:2, alegría:3, positivo:3, sorpres...</td>\n",
       "      <td>0</td>\n",
       "      <td>positivo:1</td>\n",
       "      <td>-1</td>\n",
       "      <td>enfado:1, anticipación:6, alegría:2, negativo:...</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0</td>\n",
       "      <td>asco:4</td>\n",
       "      <td>News &amp; Politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comentario              Autor  \\\n",
       "3746                                  Plata desapareció  @piglinslayer5159   \n",
       "2638  Buen reporte gracias, votante orgullosa ser ur...        @soguma2011   \n",
       "\n",
       "      Likes_Comentario Fecha_Publicacion_Comentario  \\\n",
       "3746                 7         2024-07-22T22:08:26Z   \n",
       "2638                11         2024-10-28T02:27:04Z   \n",
       "\n",
       "                                        URL_Video  \\\n",
       "3746  https://www.youtube.com/watch?v=NMf3uKHuTTs   \n",
       "2638  https://www.youtube.com/watch?v=lxkUpiOCM9k   \n",
       "\n",
       "                                           Titulo_Video  \\\n",
       "3746  álvaro delgado pidió renuncia intendente artig...   \n",
       "2638  ballottage uruguay segunda vuelta candidatos d...   \n",
       "\n",
       "                                      Descripcion_Video  \\\n",
       "3746  tras ser condenado caso investiga cobro irregu...   \n",
       "2638  millones ciudadanos uruguayos asisten domingo ...   \n",
       "\n",
       "                                                   Tags  \\\n",
       "3746                                                NaN   \n",
       "2638  canal noticias canal argentina canal noticias ...   \n",
       "\n",
       "     Fecha_Publicacion_Video  Idioma  ...  \\\n",
       "3746    2024-07-22T17:27:10Z  es-419  ...   \n",
       "2638    2024-10-28T01:38:41Z  es-419  ...   \n",
       "\n",
       "                                         Comentario_nrc  Titulo_Video_afinn  \\\n",
       "3746                                                NaN                  -1   \n",
       "2638  anticipación:2, alegría:3, positivo:3, sorpres...                   0   \n",
       "\n",
       "            Titulo_Video_nrc  Descripcion_Video_afinn  \\\n",
       "3746  positivo:1, negativo:1                       -4   \n",
       "2638              positivo:1                       -1   \n",
       "\n",
       "                                  Descripcion_Video_nrc  Comentario_Polaridad  \\\n",
       "3746  miedo:2, negativo:4, tristeza:2, positivo:4, a...                  0.00   \n",
       "2638  enfado:1, anticipación:6, alegría:2, negativo:...                  0.52   \n",
       "\n",
       "     Comentario_Subjetividad  Tags_afinn Tags_nrc  Categoria_Nombre  \n",
       "3746                   0.000           0      NaN   News & Politics  \n",
       "2638                   0.645           0   asco:4   News & Politics  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee38b5c9",
   "metadata": {},
   "source": [
    "# Rescatar Tags, Paises y Emociones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "228de388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resumen guardado en 'resumen_emociones_nrc.csv'\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Inicializa un contador para sumar las emociones\n",
    "contador_emociones = Counter()\n",
    "\n",
    "# Recorremos cada fila de la columna\n",
    "for fila in df['Comentario_nrc'].dropna():\n",
    "    emociones = fila.split(',')  # Separar por coma\n",
    "    for emocion in emociones:\n",
    "        emocion = emocion.strip()\n",
    "        if ':' in emocion:\n",
    "            clave, valor = emocion.split(':')\n",
    "            clave = clave.strip().lower()\n",
    "            try:\n",
    "                valor = int(valor.strip())\n",
    "                contador_emociones[clave] += valor\n",
    "            except ValueError:\n",
    "                continue  # Ignora si no puede convertir el valor\n",
    "\n",
    "# Convertimos el contador a DataFrame ordenado\n",
    "resumen_df = pd.DataFrame(contador_emociones.items(), columns=['Emocion', 'Total'])\n",
    "resumen_df = resumen_df.sort_values(by='Total', ascending=False)\n",
    "\n",
    "# Guardar el resumen como CSV\n",
    "resumen_df.to_csv('resumen_emociones_nrc.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"✅ Resumen guardado en 'resumen_emociones_nrc.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d5c5ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# 2. Procesar columna Tags y contar los más frecuentes\n",
    "def contar_tags(df, columna='Tags'):\n",
    "    todos_los_tags = []\n",
    "\n",
    "    for tags in df[columna].dropna():\n",
    "        # Separar tags por espacio\n",
    "        separados = tags.split()\n",
    "        todos_los_tags.extend(separados)\n",
    "\n",
    "    # Contar frecuencia con Counter\n",
    "    conteo = Counter(todos_los_tags)\n",
    "    df_resultado = pd.DataFrame(conteo.items(), columns=['Tag', 'Frecuencia'])\n",
    "    df_resultado = df_resultado.sort_values(by='Frecuencia', ascending=False).reset_index(drop=True)\n",
    "    return df_resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1fdda78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['UY' 'AR' nan 'US' 'PE' 'FR' 'ES' 'DE' 'IN' 'CO' 'EC' 'MX' 'VE']\n",
      "   País  Frecuencia  Porcentaje\n",
      "0    UY        3642   68.484393\n",
      "1    AR        1014   19.067319\n",
      "2    US         215    4.042873\n",
      "3    FR         136    2.557352\n",
      "4    DE          86    1.617149\n",
      "5    ES          29    0.545318\n",
      "6    CO          19    0.357277\n",
      "7    IN           3    0.056412\n",
      "8    MX           3    0.056412\n",
      "9    EC           2    0.037608\n",
      "10   PE           1    0.018804\n",
      "11   VE           1    0.018804\n"
     ]
    }
   ],
   "source": [
    "print(df['Pais_Canal'].unique())\n",
    "conteo_paises = df['Pais_Canal'].value_counts().reset_index()\n",
    "conteo_paises.columns = ['País', 'Frecuencia']  # Renombrar columnas\n",
    "conteo_paises['Porcentaje'] = (conteo_paises['Frecuencia'] / len(df)) * 100  # Añadir porcentaje\n",
    "\n",
    "print(conteo_paises)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2f064d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Tags más frecuentes:\n",
      "\n",
      "           Tag  Frecuencia\n",
      "0      uruguay       10079\n",
      "1       debate        8669\n",
      "2      delgado        4286\n",
      "3         orsi        4076\n",
      "4     analisis        3364\n",
      "5       alvaro        3240\n",
      "6         vivo        3216\n",
      "7        pisso        2103\n",
      "8       franco        2103\n",
      "9    encuestas        1882\n",
      "10  elecciones        1878\n",
      "11     yamandu        1512\n",
      "12    noticias        1327\n",
      "13  presidente        1200\n",
      "14     yamandú        1082\n",
      "15    balotaje         948\n",
      "16  observador         715\n",
      "17    análisis         709\n",
      "18          uy         701\n",
      "19        pais         701\n",
      "✅ Archivo CSV guardado como: tags_contados.csv\n"
     ]
    }
   ],
   "source": [
    "df_tags = contar_tags(df)\n",
    "print(\"\\n🎯 Tags más frecuentes:\\n\")\n",
    "print(df_tags.head(20))  \n",
    "# Guardar como CSV en la misma carpeta del notebook\n",
    "df_tags.to_csv(\"tags_contados.csv\", index=False)\n",
    "print(\"✅ Archivo CSV guardado como: tags_contados.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e3d6ac",
   "metadata": {},
   "source": [
    "## Viztazo a los Datos: reporte_datos.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b6858369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_comentarios(df, log):\n",
    "    log.append(\"\\n🔍 Tipo real de objetos en la columna 'Comentario':\")\n",
    "    tipos = df['Comentario'].map(type).value_counts()\n",
    "    log.append(str(tipos))\n",
    "\n",
    "    log.append(\"\\n⚠️ Ejemplos de valores no str (si existen):\")\n",
    "    no_str = df[~df['Comentario'].map(lambda x: isinstance(x, str))]\n",
    "    log.append(str(no_str.head()))\n",
    "\n",
    "    \n",
    "\n",
    "def analizar_calidad_datos(df, log):\n",
    "    log.append(\"\\n📊 INFORME GENERAL DEL DATAFRAME\")\n",
    "    log.append(f\"Filas: {df.shape[0]}, Columnas: {df.shape[1]}\")\n",
    "\n",
    "    log.append(\"\\n🧠 Tipos de datos por columna:\")\n",
    "    log.append(str(df.dtypes))\n",
    "\n",
    "    log.append(\"\\n🔎 Valores únicos por columna:\")\n",
    "    log.append(str(df.nunique()))\n",
    "\n",
    "    log.append(\"\\n🚫 Conteo de valores nulos (NaN) por columna:\")\n",
    "    log.append(str(df.isna().sum()))\n",
    "\n",
    "    log.append(\"\\n📉 Porcentaje de valores nulos por columna:\")\n",
    "    log.append(str((df.isna().mean() * 100).round(2).astype(str) + '%'))\n",
    "\n",
    "\n",
    "def guardar_log(log):\n",
    "    with open(\"reporte_datos.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for linea in log:\n",
    "            f.write(str(linea) + \"\\n\")\n",
    "    print(\"📄 Informe guardado como 'reporte_datos.txt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9e1c63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Informe guardado como 'reporte_datos.txt'\n"
     ]
    }
   ],
   "source": [
    "log = []\n",
    "analizar_calidad_datos(df, log)\n",
    "if 'Comentario' in df.columns:\n",
    "    analizar_comentarios(df, log)\n",
    "else:\n",
    "    log.append(\"\\n❌ La columna 'Comentario' no está en el archivo.\")\n",
    "\n",
    "guardar_log(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260f573",
   "metadata": {},
   "source": [
    "## PreProcesamiento de Datos para Machine Learning: ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8370542e",
   "metadata": {},
   "source": [
    "| **Columna**                    | **¿Usable?** | **Cómo procesarla / convertirla**                                 |\n",
    "| ------------------------------ | ------------ | ----------------------------------------------------------------- |\n",
    "| `Comentario`                   | ✅            | NLP: limpiar, tokenizar, vectorizar (TF-IDF, embeddings)          |\n",
    "| `Autor`                        | 🔸           | Poco útil directamente; posible usar como frecuencia si se repite |\n",
    "| `Likes_Comentario`             | ✅            | Escalar (MinMaxScaler o StandardScaler)                           |\n",
    "| `Fecha_Publicacion_Comentario` | ✅            | Extraer año, mes, día, hora como nuevas columnas                  |\n",
    "| `URL_Video`                    | ❌            | No útil para ML; solo identificador                               |\n",
    "| `Titulo_Video`                 | ✅            | NLP: igual que `Comentario`                                       |\n",
    "| `Descripcion_Video`            | ✅            | NLP: igual que `Comentario`                                       |\n",
    "| `Tags`                         | ✅            | Tokenizar, contar palabras clave, binarizar o vectorizar          |\n",
    "| `Fecha_Publicacion_Video`      | ✅            | Extraer año, mes, hora para análisis temporal                     |\n",
    "| `Idioma`                       | ✅            | Codificar como categórica (One-Hot o LabelEncoding)               |\n",
    "| `Duracion`                     | ✅            | Convertir de ISO 8601 (`PT2H50M25S`) a minutos totales            |\n",
    "| `Numero_Views`                 | ✅            | Escalar                                                           |\n",
    "| `Numero_Likes`                 | ✅            | Escalar                                                           |\n",
    "| `Numero_Comentarios`           | ✅            | Escalar                                                           |\n",
    "| `Pais_Canal`                   | ✅            | Codificar país (categórica)                                       |\n",
    "| `Subscriptores_Canal`          | ✅            | Escalar                                                           |\n",
    "| `Canal_Titulo`                 | 🔸           | Útil si se agrupa o analiza como canal dominante                  |\n",
    "| `Comentario_afinn`             | ✅            | Escalar (sentimiento ya numerizado)                               |\n",
    "| `Comentario_nrc`               | ✅            | Contar emociones y expandir como columnas: alegría, miedo, etc.   |\n",
    "| `Titulo_Video_afinn`           | ✅            | Escalar                                                           |\n",
    "| `Titulo_Video_nrc`             | ✅            | Igual que `Comentario_nrc`                                        |\n",
    "| `Descripcion_Video_afinn`      | ✅            | Escalar                                                           |\n",
    "| `Descripcion_Video_nrc`        | ✅            | Igual que `Comentario_nrc`                                        |\n",
    "| `Comentario_Polaridad`         | ✅            | Escalar (valor entre -1 y 1)                                      |\n",
    "| `Comentario_Subjetividad`      | ✅            | Escalar (valor entre 0 y 1)                                       |\n",
    "| `Tags_afinn`                   | ✅            | Escalar                                                           |\n",
    "| `Tags_nrc`                     | ✅            | Expandir emociones como columnas                                  |\n",
    "| `Categoria_Nombre`             | ✅            | Codificar como variable categórica                                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0fec227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Eliminar columnas específicas ---\n",
    "def eliminar_columnas(df, columnas_a_eliminar, log):\n",
    "    columnas_eliminadas = [col for col in columnas_a_eliminar if col in df.columns]\n",
    "    df = df.drop(columns=columnas_eliminadas, errors='ignore')\n",
    "    log.append(f\"🗑️ Columnas eliminadas: {columnas_eliminadas}\")\n",
    "    return df\n",
    "def ponderar_pais(df, columna):\n",
    "    total_paises = df[columna].dropna().value_counts(normalize=True)\n",
    "    ponderacion = df[columna].map(total_paises).fillna(0)\n",
    "    return ponderacion\n",
    "def parsear_duracion_iso8601(duracion):\n",
    "    if not isinstance(duracion, str) or not duracion.startswith('PT'):\n",
    "        return 0\n",
    "    horas = minutos = segundos = 0\n",
    "\n",
    "    match_h = re.search(r'(\\d+)H', duracion)\n",
    "    match_m = re.search(r'(\\d+)M', duracion)\n",
    "    match_s = re.search(r'(\\d+)S', duracion)\n",
    "\n",
    "    if match_h:\n",
    "        horas = int(match_h.group(1))\n",
    "    if match_m:\n",
    "        minutos = int(match_m.group(1))\n",
    "    if match_s:\n",
    "        segundos = int(match_s.group(1))\n",
    "\n",
    "    total_segundos = horas * 3600 + minutos * 60 + segundos\n",
    "    return total_segundos\n",
    "def ponderar_categoria(df):\n",
    "    # Diccionario de pesos por categoría PONDERACION OBTENIDA GRACIAS A CHATGPT 4o\n",
    "    pesos_categoria = {\n",
    "        \"News & Politics\": 1.0,\n",
    "        \"Education\": 0.8,\n",
    "        \"People & Blogs\": 0.7,\n",
    "        \"Entertainment\": 0.6,\n",
    "        \"Comedy\": 0.6,\n",
    "        \"Music\": 0.5,\n",
    "        \"Howto & Style\": 0.5,\n",
    "        \"Science & Technology\": 0.7,\n",
    "        \"Sports\": 0.4,\n",
    "        \"Gaming\": 0.3,\n",
    "        \"Film & Animation\": 0.4,\n",
    "        \"Autos & Vehicles\": 0.2,\n",
    "        \"Pets & Animals\": 0.2,\n",
    "        \"Travel & Events\": 0.3,\n",
    "        \"Videoblogging\": 0.5,\n",
    "        \"Short Movies\": 0.4,\n",
    "        \"Movies\": 0.3,\n",
    "        \"Nonprofits & Activism\": 0.6,\n",
    "        \"Anime/Animation\": 0.3,\n",
    "        \"Action/Adventure\": 0.3,\n",
    "        \"Classics\": 0.3,\n",
    "        \"Comedy (Movies)\": 0.5,\n",
    "        \"Documentary\": 0.7,\n",
    "        \"Drama\": 0.4,\n",
    "        \"Family\": 0.4,\n",
    "        \"Foreign\": 0.3,\n",
    "        \"Horror\": 0.3,\n",
    "        \"Sci-Fi/Fantasy\": 0.3,\n",
    "        \"Thriller\": 0.3,\n",
    "        \"Shorts\": 0.4,\n",
    "        \"Shows\": 0.4,\n",
    "        \"Trailers\": 0.2\n",
    "    }\n",
    "\n",
    "    # Asigna el peso según la categoría (NaN si no está en el diccionario)\n",
    "    df['Categoria_Ponderada'] = df['Categoria_Nombre'].map(pesos_categoria)\n",
    "\n",
    "    # Rellena valores faltantes con un peso neutro o bajo, por ejemplo 0.3\n",
    "    df['Categoria_Ponderada'] = df['Categoria_Ponderada'].fillna(0.3)\n",
    "\n",
    "    # Elimina la columna original\n",
    "    df.drop(columns=['Categoria_Nombre'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# --- Rellenar valores nulos ---\n",
    "def rellenar_nulos(df, log):\n",
    "    log.append(\"\\n🧽 Relleno de valores nulos:\")\n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            if df[col].dtype == 'object':\n",
    "                if df[col].nunique() < 30:\n",
    "                    modo = df[col].mode(dropna=True)\n",
    "                    valor = modo[0] if not modo.empty else \"desconocido\"\n",
    "                    df[col] = df[col].fillna(valor)\n",
    "                    log.append(f\"  - {col}: categórica → rellenado con '{valor}'\")\n",
    "                else:\n",
    "                    df[col] = df[col].fillna(\"\")\n",
    "                    log.append(f\"  - {col}: texto → rellenado con cadena vacía\")\n",
    "            elif np.issubdtype(df[col].dtype, np.number):\n",
    "                mediana = df[col].median()\n",
    "                df[col] = df[col].fillna(mediana)\n",
    "                log.append(f\"  - {col}: numérica → rellenado con mediana ({mediana})\")\n",
    "    return df\n",
    "\n",
    "# --- Expandir columnas _nrc a columnas de emociones individuales ---\n",
    "def expandir_emociones_nrc(df, log):\n",
    "    columnas_nrc = [col for col in df.columns if col.endswith('_nrc')]\n",
    "    emociones_total = set()\n",
    "\n",
    "    log.append(\"\\n🌈 Expansión de columnas _nrc:\")\n",
    "    for col in columnas_nrc:\n",
    "        log.append(f\"  - Procesando columna: {col}\")\n",
    "        emociones_dicts = df[col].fillna(\"\").apply(lambda x: {\n",
    "            k.strip(): int(v) for k, v in (item.split(\":\") for item in x.split(\",\") if \":\" in item)\n",
    "        })\n",
    "\n",
    "        emociones_col = set()\n",
    "        for dic in emociones_dicts:\n",
    "            emociones_col.update(dic.keys())\n",
    "        emociones_total.update(emociones_col)\n",
    "\n",
    "        for emocion in emociones_col:\n",
    "            df[f\"{col}_{emocion}\"] = emociones_dicts.apply(lambda d: d.get(emocion, 0))\n",
    "\n",
    "        df.drop(columns=[col], inplace=True)\n",
    "\n",
    "    log.append(f\"  - Emociones detectadas: {sorted(list(emociones_total))}\")\n",
    "    return df\n",
    "\n",
    "# --- Guardar resumen del procesamiento ---\n",
    "def guardar_resumen(log, ruta_salida_base):\n",
    "    resumen_path = f\"{ruta_salida_base}_resumen_procesamiento.txt\"\n",
    "    with open(resumen_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for linea in log:\n",
    "            f.write(linea + \"\\n\")\n",
    "    print(f\"📄 Resumen guardado como: {resumen_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541648f5",
   "metadata": {},
   "source": [
    "### Manejo de fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11302f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Asegúrate de que la columna sea tipo datetime\n",
    "df['Fecha_Publicacion_Comentario'] = pd.to_datetime(df['Fecha_Publicacion_Comentario'], errors='coerce')\n",
    "\n",
    "# 1. Extraer componentes temporales (útiles para estacionalidad y análisis temporal)\n",
    "df['comentario_anio'] = df['Fecha_Publicacion_Comentario'].dt.year\n",
    "df['comentario_mes'] = df['Fecha_Publicacion_Comentario'].dt.month\n",
    "df['comentario_dia'] = df['Fecha_Publicacion_Comentario'].dt.day\n",
    "df['comentario_dia_semana'] = df['Fecha_Publicacion_Comentario'].dt.weekday  # Lunes = 0\n",
    "df['comentario_hora'] = df['Fecha_Publicacion_Comentario'].dt.hour\n",
    "\n",
    "# 2. Convertir a timestamp numérico (útil para modelos que capturan tendencia temporal)\n",
    "# Esto convierte la fecha a segundos desde 1970-01-01 (Unix Epoch)\n",
    "df['comentario_timestamp'] = df['Fecha_Publicacion_Comentario'].astype('int64') // 10**9\n",
    "\n",
    "# (Opcional) Revisar si alguna fila no pudo convertirse correctamente\n",
    "errores_fecha = df['Fecha_Publicacion_Comentario'].isnull().sum()\n",
    "if errores_fecha > 0:\n",
    "    print(f\"⚠️ Atención: {errores_fecha} valores no pudieron convertirse a datetime.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c19bb623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.preprocessing import MinMaxScaler\\nscaler = MinMaxScaler()\\ndf['comentario_timestamp_norm'] = scaler.fit_transform(df[['comentario_timestamp']])\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##PARA REDES NEURONALES O REGRESION LINEAL\n",
    "'''from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df['comentario_timestamp_norm'] = scaler.fit_transform(df[['comentario_timestamp']])'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "175a9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Resumen guardado como: comentarios_Alvaro Delgado Uruguay_procesado_Ortografiado_sentimiento_analizado_ML_resumen_procesamiento.txt\n",
      "✅ Procesamiento finalizado.\n"
     ]
    }
   ],
   "source": [
    "# --- BLOQUE DE EJECUCIÓN PARA NOTEBOOK ---\n",
    "\n",
    "log = [f\"📂 Procesando DataFrame desde ruta: {ruta}.csv\"]\n",
    "\n",
    "# Paso 1: Eliminar columnas no deseadas\n",
    "columnas_a_eliminar = [\n",
    "    'Comentario', 'Titulo_Video', 'Descripcion_Video',\n",
    "    'Fecha_Publicacion_Video', 'Idioma','Autor','URL_Video','Tags','Canal_Titulo','Fecha_Publicacion_Comentario'\n",
    "]\n",
    "df = eliminar_columnas(df, columnas_a_eliminar, log)\n",
    "\n",
    "# Paso 2: Rellenar valores nulos\n",
    "df = rellenar_nulos(df, log)\n",
    "# Ponderar países\n",
    "df['Ponderacion_Pais_Canal'] = ponderar_pais(df, 'Pais_Canal')\n",
    "df = df.drop(columns=['Pais_Canal'], errors='ignore')\n",
    "# Paso 3: Expandir emociones NRC\n",
    "df = expandir_emociones_nrc(df, log)\n",
    "df= ponderar_categoria(df)\n",
    "# Parsear Duracion\n",
    "df['Duracion_Segundos'] = df['Duracion'].apply(parsear_duracion_iso8601)\n",
    "df = df.drop(columns=['Duracion'])  # opcional: elimina columna original\n",
    "# Paso 4: Guardar CSV y resumen\n",
    "ruta_salida_base = ruta + \"_ML\"\n",
    "df.to_csv(f\"{ruta_salida_base}.csv\", index=False, encoding='utf-8-sig')\n",
    "log.append(f\"\\n💾 Archivo final guardado como: {ruta_salida_base}.csv\")\n",
    "\n",
    "guardar_resumen(log, ruta_salida_base)\n",
    "\n",
    "print(\"✅ Procesamiento finalizado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6404a84",
   "metadata": {},
   "source": [
    "# Features Derivados recomendados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89314e13",
   "metadata": {},
   "source": [
    "Ponderación del Comentario\n",
    "\n",
    "Ponderador = (Likes_Comentario + 1) / (Numero_Comentarios + 1)\n",
    "→ Más peso a comentarios más relevantes dentro de su contexto.\n",
    "\n",
    "Engagement del Video\n",
    "\n",
    "Engagement = (Numero_Likes + Numero_Comentarios) / (Numero_Views + 1)\n",
    "→ Refleja cuánto interactúa el público con ese video.\n",
    "\n",
    "Influencia del Canal\n",
    "\n",
    "Influencia_Canal = log(Subscriptores_Canal + 1)\n",
    "→ Escala logarítmica para evitar distorsión por canales gigantes.\n",
    "\n",
    "Polaridad ponderada\n",
    "\n",
    "Comentario_Polaridad_Ponderada = Comentario_Polaridad * Ponderador\n",
    "\n",
    "Subjetividad ponderada\n",
    "\n",
    "Comentario_Subjetividad_Ponderada = Comentario_Subjetividad * Ponderador\n",
    "\n",
    "AFINN ponderado\n",
    "\n",
    "Comentario_afinn_Ponderado = Comentario_afinn * Ponderador\n",
    "\n",
    "Emoción codificada (One-hot o embedding)\n",
    "→ Convertir Comentario_nrc_emocion a variables binarias como:\n",
    "\n",
    "emocion_positivo, emocion_miedo, emocion_confianza, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bfb6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def crear_features_avanzados(df):\n",
    "    # Prevenir división por cero\n",
    "    df['Likes_Comentario'] = df['Likes_Comentario'].fillna(0)\n",
    "    df['Numero_Comentarios'] = df['Numero_Comentarios'].replace(0, np.nan)\n",
    "    df['Numero_Views'] = df['Numero_Views'].replace(0, np.nan)\n",
    "    df['Numero_Likes'] = df['Numero_Likes'].replace(0, np.nan)\n",
    "    df['Subscriptores_Canal'] = df['Subscriptores_Canal'].replace(0, np.nan)\n",
    "\n",
    "    # --- 1. Ponderador del Comentario ---\n",
    "    df['Ponderador_Comentario'] = (df['Likes_Comentario'] + 1) / (df['Numero_Comentarios'] + 1)\n",
    "\n",
    "    # --- 2. Engagement del Video ---\n",
    "    df['Engagement_Video'] = (df['Numero_Likes'] + df['Numero_Comentarios']) / (df['Numero_Views'] + 1)\n",
    "\n",
    "    # --- 3. Influencia del Canal ---\n",
    "    df['Influencia_Canal'] = np.log1p(df['Subscriptores_Canal'])  # log(Subscriptores_Canal + 1)\n",
    "\n",
    "    # --- 4. Polaridad y Subjetividad Ponderadas ---\n",
    "    df['Comentario_Polaridad_Ponderada'] = df['Comentario_Polaridad'] * df['Ponderador_Comentario']\n",
    "    df['Comentario_Subjetividad_Ponderada'] = df['Comentario_Subjetividad'] * df['Ponderador_Comentario']\n",
    "\n",
    "    # --- 5. AFINN Ponderado ---\n",
    "    df['Comentario_afinn_Ponderado'] = df['Comentario_afinn'] * df['Ponderador_Comentario']\n",
    "    df['Titulo_Video_afinn_Ponderado'] = df['Titulo_Video_afinn'] * df['Engagement_Video']\n",
    "    df['Descripcion_Video_afinn_Ponderado'] = df['Descripcion_Video_afinn'] * df['Engagement_Video']\n",
    "    df['Tags_afinn_Ponderado'] = df['Tags_afinn'] * df['Influencia_Canal']\n",
    "\n",
    "    # --- 6. Emociones NRC Ponderadas ---\n",
    "    emociones = [\n",
    "        'alegría', 'anticipación', 'enfado', 'tristeza', 'positivo', 'sorpresa',\n",
    "        'asco', 'negativo', 'confianza', 'miedo'\n",
    "    ]\n",
    "    fuentes = ['Comentario_', 'Titulo_Video_', 'Descripcion_Video_', 'Tags_']\n",
    "\n",
    "    for emocion in emociones:\n",
    "        for fuente in fuentes:\n",
    "            col = f'{fuente}nrc_{emocion}'\n",
    "            if col in df.columns:\n",
    "                nueva_col = f'{col}_Ponderada'\n",
    "                if fuente == 'Comentario_':\n",
    "                    df[nueva_col] = df[col] * df['Ponderador_Comentario']\n",
    "                elif fuente == 'Titulo_Video_' or fuente == 'Descripcion_Video_':\n",
    "                    df[nueva_col] = df[col] * df['Engagement_Video']\n",
    "                else:\n",
    "                    df[nueva_col] = df[col] * df['Influencia_Canal']\n",
    "\n",
    "    # --- 7. Rellenar nulos generados ---\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fee1fe9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13876\\2504438377.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[nueva_col] = df[col] * df['Engagement_Video']\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13876\\2504438377.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[nueva_col] = df[col] * df['Influencia_Canal']\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13876\\2504438377.py:41: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[nueva_col] = df[col] * df['Ponderador_Comentario']\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13876\\2504438377.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[nueva_col] = df[col] * df['Engagement_Video']\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13876\\2504438377.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[nueva_col] = df[col] * df['Engagement_Video']\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13876\\2504438377.py:45: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[nueva_col] = df[col] * df['Influencia_Canal']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Likes_Comentario</th>\n",
       "      <th>Numero_Views</th>\n",
       "      <th>Numero_Likes</th>\n",
       "      <th>Numero_Comentarios</th>\n",
       "      <th>Subscriptores_Canal</th>\n",
       "      <th>Comentario_afinn</th>\n",
       "      <th>Titulo_Video_afinn</th>\n",
       "      <th>Descripcion_Video_afinn</th>\n",
       "      <th>Comentario_Polaridad</th>\n",
       "      <th>Comentario_Subjetividad</th>\n",
       "      <th>...</th>\n",
       "      <th>Descripcion_Video_nrc_negativo_Ponderada</th>\n",
       "      <th>Tags_nrc_negativo_Ponderada</th>\n",
       "      <th>Comentario_nrc_confianza_Ponderada</th>\n",
       "      <th>Titulo_Video_nrc_confianza_Ponderada</th>\n",
       "      <th>Descripcion_Video_nrc_confianza_Ponderada</th>\n",
       "      <th>Tags_nrc_confianza_Ponderada</th>\n",
       "      <th>Comentario_nrc_miedo_Ponderada</th>\n",
       "      <th>Titulo_Video_nrc_miedo_Ponderada</th>\n",
       "      <th>Descripcion_Video_nrc_miedo_Ponderada</th>\n",
       "      <th>Tags_nrc_miedo_Ponderada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>3</td>\n",
       "      <td>3735</td>\n",
       "      <td>77.0</td>\n",
       "      <td>18</td>\n",
       "      <td>65500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4303</th>\n",
       "      <td>4</td>\n",
       "      <td>62166</td>\n",
       "      <td>2575.0</td>\n",
       "      <td>778</td>\n",
       "      <td>140000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>0</td>\n",
       "      <td>824</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14</td>\n",
       "      <td>118000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.378182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.031515</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>0</td>\n",
       "      <td>62166</td>\n",
       "      <td>2575.0</td>\n",
       "      <td>778</td>\n",
       "      <td>140000</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0</td>\n",
       "      <td>142420</td>\n",
       "      <td>13421.0</td>\n",
       "      <td>1294</td>\n",
       "      <td>1190000</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.947324</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.10332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>3</td>\n",
       "      <td>6826</td>\n",
       "      <td>73.0</td>\n",
       "      <td>48</td>\n",
       "      <td>118000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.177237</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>0</td>\n",
       "      <td>54039</td>\n",
       "      <td>611.0</td>\n",
       "      <td>527</td>\n",
       "      <td>56400</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252702</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.126351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1</td>\n",
       "      <td>6714</td>\n",
       "      <td>129.0</td>\n",
       "      <td>87</td>\n",
       "      <td>56400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.096500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>142420</td>\n",
       "      <td>13421.0</td>\n",
       "      <td>1294</td>\n",
       "      <td>1190000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.947324</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.10332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5240</th>\n",
       "      <td>0</td>\n",
       "      <td>26467</td>\n",
       "      <td>312.0</td>\n",
       "      <td>442</td>\n",
       "      <td>3280</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.203030</td>\n",
       "      <td>0.324242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013544</td>\n",
       "      <td>0.028487</td>\n",
       "      <td>0.256385</td>\n",
       "      <td>32.383614</td>\n",
       "      <td>0.011287</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.056974</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Likes_Comentario  Numero_Views  Numero_Likes  Numero_Comentarios  \\\n",
       "3624                 3          3735          77.0                  18   \n",
       "4303                 4         62166        2575.0                 778   \n",
       "3857                 0           824          12.0                  14   \n",
       "4107                 0         62166        2575.0                 778   \n",
       "204                  0        142420       13421.0                1294   \n",
       "1406                 3          6826          73.0                  48   \n",
       "926                  0         54039         611.0                 527   \n",
       "1459                 1          6714         129.0                  87   \n",
       "253                  1        142420       13421.0                1294   \n",
       "5240                 0         26467         312.0                 442   \n",
       "\n",
       "      Subscriptores_Canal  Comentario_afinn  Titulo_Video_afinn  \\\n",
       "3624                65500                 1                   0   \n",
       "4303               140000                 0                   0   \n",
       "3857               118000                 0                   0   \n",
       "4107               140000                -3                   0   \n",
       "204               1190000                 2                  -1   \n",
       "1406               118000                 0                   0   \n",
       "926                 56400                -1                   0   \n",
       "1459                56400                 0                   0   \n",
       "253               1190000                 0                  -1   \n",
       "5240                 3280                 9                   0   \n",
       "\n",
       "      Descripcion_Video_afinn  Comentario_Polaridad  Comentario_Subjetividad  \\\n",
       "3624                        0              0.000000                 0.000000   \n",
       "4303                        0             -0.166667                 0.066667   \n",
       "3857                       12             -0.600000                 0.800000   \n",
       "4107                        0             -0.500000                 1.000000   \n",
       "204                         0              0.100000                 0.350000   \n",
       "1406                       15              0.000000                 0.100000   \n",
       "926                         8              0.600000                 0.900000   \n",
       "1459                        0              0.000000                 0.000000   \n",
       "253                         0              0.000000                 0.500000   \n",
       "5240                        8              0.203030                 0.324242   \n",
       "\n",
       "      ...  Descripcion_Video_nrc_negativo_Ponderada  \\\n",
       "3624  ...                                  0.000000   \n",
       "4303  ...                                  0.000000   \n",
       "3857  ...                                  0.094545   \n",
       "4107  ...                                  0.000000   \n",
       "204   ...                                  0.000000   \n",
       "1406  ...                                  0.354475   \n",
       "926   ...                                  0.252702   \n",
       "1459  ...                                  0.096500   \n",
       "253   ...                                  0.000000   \n",
       "5240  ...                                  0.085462   \n",
       "\n",
       "      Tags_nrc_negativo_Ponderada  Comentario_nrc_confianza_Ponderada  \\\n",
       "3624                          0.0                            0.000000   \n",
       "4303                          0.0                            0.019255   \n",
       "3857                          0.0                            0.000000   \n",
       "4107                          0.0                            0.000000   \n",
       "204                           0.0                            0.000000   \n",
       "1406                          0.0                            0.081633   \n",
       "926                           0.0                            0.000000   \n",
       "1459                          0.0                            0.000000   \n",
       "253                           0.0                            0.003089   \n",
       "5240                          0.0                            0.013544   \n",
       "\n",
       "      Titulo_Video_nrc_confianza_Ponderada  \\\n",
       "3624                              0.025428   \n",
       "4303                              0.000000   \n",
       "3857                              0.000000   \n",
       "4107                              0.000000   \n",
       "204                               0.000000   \n",
       "1406                              0.000000   \n",
       "926                               0.000000   \n",
       "1459                              0.000000   \n",
       "253                               0.000000   \n",
       "5240                              0.028487   \n",
       "\n",
       "      Descripcion_Video_nrc_confianza_Ponderada  Tags_nrc_confianza_Ponderada  \\\n",
       "3624                                   0.000000                      0.000000   \n",
       "4303                                   0.000000                      0.000000   \n",
       "3857                                   0.378182                      0.000000   \n",
       "4107                                   0.000000                      0.000000   \n",
       "204                                    0.000000                     69.947324   \n",
       "1406                                   0.425370                      0.000000   \n",
       "926                                    0.231643                      0.000000   \n",
       "1459                                   0.257334                      0.000000   \n",
       "253                                    0.000000                     69.947324   \n",
       "5240                                   0.256385                     32.383614   \n",
       "\n",
       "      Comentario_nrc_miedo_Ponderada  Titulo_Video_nrc_miedo_Ponderada  \\\n",
       "3624                        0.000000                           0.00000   \n",
       "4303                        0.000000                           0.00000   \n",
       "3857                        0.000000                           0.00000   \n",
       "4107                        0.000000                           0.00000   \n",
       "204                         0.000000                           0.10332   \n",
       "1406                        0.000000                           0.00000   \n",
       "926                         0.001894                           0.00000   \n",
       "1459                        0.000000                           0.00000   \n",
       "253                         0.004633                           0.10332   \n",
       "5240                        0.011287                           0.00000   \n",
       "\n",
       "      Descripcion_Video_nrc_miedo_Ponderada  Tags_nrc_miedo_Ponderada  \n",
       "3624                               0.000000                       0.0  \n",
       "4303                               0.000000                       0.0  \n",
       "3857                               0.031515                       0.0  \n",
       "4107                               0.000000                       0.0  \n",
       "204                                0.000000                       0.0  \n",
       "1406                               0.177237                       0.0  \n",
       "926                                0.126351                       0.0  \n",
       "1459                               0.096500                       0.0  \n",
       "253                                0.000000                       0.0  \n",
       "5240                               0.056974                       0.0  \n",
       "\n",
       "[10 rows x 109 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features= crear_features_avanzados(df)\n",
    "df_features.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb8aec31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Archivo final guardado como: comentarios_Alvaro Delgado Uruguay_procesado_Ortografiado_sentimiento_analizado_ML_fealtures.csv\n"
     ]
    }
   ],
   "source": [
    "ruta_salida_fealtures = ruta_salida_base + \"_fealtures\"\n",
    "df_features.to_csv(f\"{ruta_salida_fealtures}.csv\", index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n💾 Archivo final guardado como: {ruta_salida_fealtures}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84eed101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna: Likes_Comentario\n",
      "[  0   1   5   4  10   2   3   8  11  12  15  13   6   9  14  21  23  27\n",
      "   7 188  29  28  87  44 100  45  18  17  22  19  16 355  75  51  41  39\n",
      "  32 130  42  49  31  34  20  57  40 103  43  47  38  24  25  30  26  33\n",
      "  35  46  37  54  36  99  48  66  65 158  71  58  98  81  94 231 102 107\n",
      "  83  64  55  84  50 113  56  60  76]\n",
      "--------------------------------------------------\n",
      "Columna: Numero_Views\n",
      "[440876 495113 386637 142420 177523  81856  84217  54039  42812  26467\n",
      "  25509  31447  44985  11821  10707  12298   6826   6714   5674   4513\n",
      "   4343   4200   3682   3660   3488   3455   3371   3123   2721   2702\n",
      "   2681   2940   2576   1921   1724   1488   1263   1258   1311   1248\n",
      "   1174   1083   1062   1011    862    839 702736 125764  96543  75373\n",
      "  30455  20242  18052  16329  16008  14335  12359  11416  10969  10157\n",
      "  10140   9404   8761   8636   8177   8033   7583   7339   7302   6453\n",
      "   6390   6233   6190   5456   4893   4636   4623  41809   4293   4203\n",
      "   4119   4015   3846   3808   3794   3665   3598  18289   3436   3416\n",
      "   3376   3264   3246   3122   3715   2932   2457   2229   1727   1188\n",
      "    701    372    268    213    180    165   3714   2572   2365   1394\n",
      "   1198   1123    993    947    942    855    761    621    576    535\n",
      "    467    449    315    246    186    167    147    130     28     26\n",
      "  15344  13924  11909   6447   5015   3792   3735   2235   1818   1701\n",
      "   1500   1495   1453   1429   1379   1492   1351   1287    754    591\n",
      "    560    474    383    339    318    304 108258   1964    824    699\n",
      "    668    496    491    255    194    191    152    146  62166  37581\n",
      "   3777   2670   2730   1898   1845   1435    840    834    782    756\n",
      "    670    580    523    420    158     13  24569   4450    381    237\n",
      "  69325  13235   4104   3236   1903   1882   1215    507    207   2529\n",
      "   2143    561    463    385     73   1520    831   1345   8009   1361\n",
      "    632    324    295     86 142429  84218  54040  24251  10167  10114\n",
      "   5537   5419   3374   1861]\n",
      "--------------------------------------------------\n",
      "Columna: Numero_Likes\n",
      "[5.0000e+02 8.8640e+03 1.0300e+02 1.3421e+04 2.8530e+03 3.8620e+03\n",
      " 1.4110e+03 6.1100e+02 0.0000e+00 3.1200e+02 5.7800e+02 1.2850e+03\n",
      " 2.4630e+03 2.0900e+02 6.6900e+02 7.3000e+01 1.2900e+02 4.5000e+01\n",
      " 1.0200e+02 6.7000e+01 3.7000e+01 2.8000e+01 4.2000e+01 8.0000e+01\n",
      " 1.1300e+02 6.0000e+01 4.9000e+01 3.4000e+01 4.8000e+01 1.4300e+02\n",
      " 1.4000e+02 9.4000e+01 7.0000e+00 1.0000e+01 2.2000e+01 1.4000e+01\n",
      " 2.0000e+02 1.1000e+01 3.1000e+01 6.8000e+01 2.1000e+01 2.3000e+01\n",
      " 3.6000e+01 3.0000e+01 1.9070e+03 1.5000e+01 3.5000e+01 8.4100e+02\n",
      " 4.7700e+02 2.8300e+02 1.4100e+02 1.1900e+02 2.5200e+02 1.0000e+02\n",
      " 1.3200e+02 2.4200e+02 3.0800e+02 1.3100e+02 3.1900e+02 1.6100e+02\n",
      " 5.9000e+01 7.5000e+01 7.8000e+01 9.5000e+01 8.3000e+01 5.2000e+01\n",
      " 1.0700e+02 4.1000e+01 6.3000e+01 5.1000e+01 2.3260e+03 2.0000e+01\n",
      " 5.3000e+01 5.4000e+01 7.4000e+01 4.3000e+01 3.3000e+01 8.3500e+02\n",
      " 3.8000e+01 5.7000e+01 4.0000e+01 1.7000e+01 1.8000e+01 1.2000e+01\n",
      " 6.0000e+00 1.0000e+00 2.0000e+00 8.2000e+01 4.6000e+01 1.3000e+01\n",
      " 8.0000e+00 9.0000e+00 4.0000e+00 5.0000e+00 2.1200e+02 8.8000e+01\n",
      " 3.3800e+02 9.9000e+01 1.0400e+02 7.7000e+01 1.9000e+01 2.4000e+01\n",
      " 4.7000e+01 1.1800e+02 2.6000e+01 2.5000e+01 2.5750e+03 2.7100e+02\n",
      " 6.5000e+01 3.0000e+00 9.7600e+02 1.2650e+03 4.2300e+02 1.1000e+02\n",
      " 4.4000e+01 2.9000e+01 8.6000e+01 3.2100e+02 2.1300e+02 9.1000e+01]\n",
      "--------------------------------------------------\n",
      "Columna: Numero_Comentarios\n",
      "[  90    3   50 1294    7    8   16  527    9  442   54   19   15  293\n",
      "   37    2   48   87   43   40  176   10   35   46   58   47   44   76\n",
      "    1   25   24   38   29   26    6   12    5   85   17   51  179  266\n",
      "   30  118   69   34  120  153  183  172  138   55   86   74   11    4\n",
      "   49   97   14   39   56   32   42   52   21   20   13   23   18  112\n",
      "  192   41   71   27  778  142  102   22   33  175  228  127   78   60\n",
      "  445   36   45]\n",
      "--------------------------------------------------\n",
      "Columna: Subscriptores_Canal\n",
      "[    5390  1190000    56400     1160     3280    65500    30100   118000\n",
      "   434000     3670  5300000   604000    70000    54400     1320     5170\n",
      "     2420    25200  2020000  6790000  1970000    35300     3190     2790\n",
      "   160000    20800     1380  3090000    47000   862000     8920  5220000\n",
      "   283000  3320000    85000  1090000 10000000  4760000  1770000   793000\n",
      "  1320000     3340    41100    44700    15800  8700000      796    52600\n",
      "    21200      662   210000     1700   172000     7830     1350     2060\n",
      "      115      973     1400    62900      726     3780   140000      691\n",
      "     5030     2490   133000     9610    74000  5230000]\n",
      "--------------------------------------------------\n",
      "\n",
      "Se han mostrado las primeras 5 columnas del DataFrame.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "contador = 0\n",
    "for columna in df.columns:\n",
    "    if contador >= 5:  # Detener después de 5 columnas\n",
    "        break\n",
    "        \n",
    "    print(f\"Columna: {columna}\")\n",
    "    print(df[columna].unique())  # Valores únicos\n",
    "    print(\"-\" * 50)  # Separador visual\n",
    "    contador += 1  # Incrementar el contador\n",
    "\n",
    "print(\"\\nSe han mostrado las primeras 5 columnas del DataFrame.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
