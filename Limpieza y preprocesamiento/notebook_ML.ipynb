{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea08311",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Script de Preprocesamiento para Gradient Boosting y Random Forest###\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e301622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar datos (reemplaza con tu dataframe)\n",
    "df = pd.read_csv('tus_datos.csv')\n",
    "# Para este ejemplo, asumiremos que df ya está cargado\n",
    "\n",
    "## 1. Preparación inicial ------------------------------------------------------\n",
    "\n",
    "# Definir si es problema de clasificación o regresión (ajusta según tu caso)\n",
    "problem_type = 'classification'  # o 'regression'\n",
    "\n",
    "# Definir variable objetivo (ajusta según tu caso)\n",
    "target_column = 'Engagement'  # Ejemplo, cambia por tu target real\n",
    "\n",
    "# Separar características y objetivo\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]\n",
    "\n",
    "# Dividir en train y test (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e655e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Preprocesamiento ---------------------------------------------------------\n",
    "\n",
    "# Identificar tipos de columnas (ajusta según tu dataset)\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Quitar columnas no relevantes (timestamp, IDs, etc.)\n",
    "cols_to_drop = ['comentario_timestamp']  # Ajusta según tu caso\n",
    "numeric_cols = [col for col in numeric_cols if col not in cols_to_drop]\n",
    "categorical_cols = [col for col in categorical_cols if col not in cols_to_drop]\n",
    "\n",
    "# Transformaciones:\n",
    "# - Escalado robusto para numéricas (mejor para datos con outliers)\n",
    "# - OneHot para categóricas con pocas categorías, TargetEncoding para muchas\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # Alternativa: RobustScaler()\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    # Para muchas categorías, considera TargetEncoding\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Pipelines completos ------------------------------------------------------\n",
    "\n",
    "# Pipeline para Random Forest\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42) if problem_type == 'classification' \n",
    "                      else RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Pipeline para XGBoost\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(random_state=42, eval_metric='logloss') if problem_type == 'classification' \n",
    "                     else XGBRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# Pipeline para LightGBM\n",
    "lgbm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LGBMClassifier(random_state=42) if problem_type == 'classification' \n",
    "                      else LGBMRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Entrenamiento y evaluación -----------------------------------------------\n",
    "\n",
    "# Diccionario de modelos\n",
    "models = {\n",
    "    'Random Forest': rf_pipeline,\n",
    "    'XGBoost': xgb_pipeline,\n",
    "    'LightGBM': lgbm_pipeline\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n--- Entrenando {name} ---\")\n",
    "    \n",
    "    # Entrenamiento\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predicción\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluación\n",
    "    if problem_type == 'classification':\n",
    "        print(f\"Resultados de {name}:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    else:\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        print(f\"MSE de {name}: {mse:.4f}\")\n",
    "    \n",
    "    # Feature importance (solo para árboles)\n",
    "    if hasattr(model.named_steps['classifier'], 'feature_importances_'):\n",
    "        # Obtener nombres de características después del preprocesamiento\n",
    "        if 'onehot' in preprocessor.named_transformers_['cat'].named_steps:\n",
    "            ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
    "            cat_features = ohe.get_feature_names_out(categorical_cols)\n",
    "            all_features = np.concatenate([numeric_cols, cat_features])\n",
    "        else:\n",
    "            all_features = numeric_cols + categorical_cols\n",
    "            \n",
    "        importances = model.named_steps['classifier'].feature_importances_\n",
    "        feat_imp = pd.Series(importances, index=all_features).sort_values(ascending=False)\n",
    "        \n",
    "        print(f\"\\nTop 10 características importantes de {name}:\")\n",
    "        print(feat_imp.head(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
